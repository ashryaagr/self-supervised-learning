{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1a41bc",
   "metadata": {},
   "source": [
    "## Gaussian Pyramid Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d89097",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2149805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from online_triplet_loss.losses import *\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import linalg\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.cluster import KMeans\n",
    "from copy import deepcopy\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59379b8b",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58420ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        \n",
    "        modules = list(models.resnet18(weights=None).children())[:-1]\n",
    "        self.model = nn.Sequential(*modules)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.model(x).squeeze()\n",
    "        x = self.linear(embed)\n",
    "        return x, embed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ea8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, flist, transform, labels):\n",
    "        \n",
    "        self.flist = flist\n",
    "        self.transform = transform\n",
    "        self.labels = np.array(labels).astype(\"int64\")\n",
    "        assert len(flist) == len(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flist)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.flist[index]\n",
    "\n",
    "        # read in the image, apply the standard transformation\n",
    "        img = self.transform(Image.open(sample))\n",
    "\n",
    "        return img, self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab20580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster the features\n",
    "def cluster_features(features, num_clusters):\n",
    "    \n",
    "    cobj = KMeans(n_clusters=num_clusters)\n",
    "    cobj.fit(features)    \n",
    "    assignments = cobj.labels_\n",
    "    \n",
    "    return assignments \n",
    "\n",
    "\n",
    "def get_cluster_info(labels):\n",
    "    \n",
    "    clusters = defaultdict(int)\n",
    "    for l in labels:\n",
    "        clusters[l] += 1\n",
    "    \n",
    "    empty = 0\n",
    "    for c in clusters:\n",
    "        if clusters[c] == 0:\n",
    "            empty += 1\n",
    "    \n",
    "    print(f\"Number of empty clusters: {empty}\")\n",
    "    plt.bar(sorted(clusters.keys()), [clusters[c] for c in sorted(clusters.keys())])\n",
    "    plt.show()\n",
    "    plt.xlabel(\"Cluster index\")\n",
    "    plt.ylabel(\"Cluster size\")\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265f6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26baa6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the augmented images\n",
    "src = \"pet/train/output\"\n",
    "flist_full = [os.path.join(src, f) for f in sorted(os.listdir(src))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68806782",
   "metadata": {},
   "source": [
    "**Steps in every epoch:**\n",
    "\n",
    "\n",
    "1. Create random labels, create a dataset, dataloader with these labels\n",
    "2. Do a forward & backward pass, using the feature vectors perform k-means clustering\n",
    "3. Use cluster assignments as the labels and redefine the dataset and dataloader\n",
    "4. Go to 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef0604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24cc01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 200\n",
    "NUM_CLUSTERS = NUM_CLASSES\n",
    "FEAT_DIM = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0426ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomResNet(num_classes=NUM_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fcb875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_EVERY = 250\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "use_full_dataset = False\n",
    "\n",
    "if use_full_dataset:\n",
    "    CLUSTER_EVERY = len(flist_full)/BATCH_SIZE\n",
    "    flist = flist_full\n",
    "else:\n",
    "    flist = random.sample(flist_full, CLUSTER_EVERY*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1387a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(flist)\n",
    "\n",
    "# create random labels\n",
    "labels = np.random.randint(low=0, high=NUM_CLASSES, size=num_samples)\n",
    "\n",
    "# create the dataset and dataloader\n",
    "NUM_WORKERS = 4\n",
    "train_dataset = PetDataset(flist, transform, labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227f80b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [00:19<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 5.3079\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "num_epochs = 5\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # accumulate embeddings to cluster them later\n",
    "    embeds = None\n",
    "    for idx, (x, y) in enumerate(tqdm(train_loader)):\n",
    "        \n",
    "        images_ = x.to(device)\n",
    "        labels_ = y.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, batch_embeds = model(images_)\n",
    "        \n",
    "        # Accumulate the embeddings\n",
    "        batch_embeds = batch_embeds.clone().detach().cpu().numpy()\n",
    "        if embeds is None:\n",
    "            embeds = batch_embeds.copy()\n",
    "        else:\n",
    "            embeds = np.concatenate([embeds, batch_embeds], axis=0)\n",
    "            \n",
    "        loss = criterion(outputs, labels_)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (idx+1) % CLUSTER_EVERY == 0:\n",
    "            break\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / CLUSTER_EVERY:.4f}')\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # perform the clustering\n",
    "    labels = cluster_features(embeds, num_clusters=NUM_CLUSTERS)  \n",
    "    \n",
    "    get_cluster_info(labels)\n",
    "\n",
    "    # re-define the dataset\n",
    "    train_dataset = PetDataset(flist, transform, labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1493065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"pet_resnet_dc_e5_c200_full.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b2034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
