{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thtfI8d0ad4q"
   },
   "source": [
    "# Download and unzip the PascalVoc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "ivkItYJooBYF",
    "outputId": "c787603f-3fcc-4c1b-ae42-c9dad86c22df"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "\n",
    "data_dir = './voc'\n",
    "\n",
    "\n",
    "train_dataset = VOCSegmentation(root=data_dir, year='2007', download=False, image_set='train')\n",
    "val_dataset = VOCSegmentation(root=data_dir, year='2007', download=False, image_set='val')\n",
    "test_dataset = VOCSegmentation(root=data_dir, year='2007', download=False, image_set='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 209\n",
      "Val set size: 213\n",
      "Test set size: 210\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Val set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKjin4TeaiYN"
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "\n",
    "run the code below to get thre dataloader objects, namely: train_loader, val_loader and test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1UV1V2XqkWf",
    "outputId": "04a90050-9610-4011-d28a-6adda25524e4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "num_classes = 21\n",
    "ignore_label = 255\n",
    "root = data_dir\n",
    "\n",
    "'''\n",
    "color map\n",
    "0=background, 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle # 6=bus, 7=car, 8=cat, 9=chair, 10=cow, 11=diningtable,\n",
    "12=dog, 13=horse, 14=motorbike, 15=person # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
    "'''\n",
    "\n",
    "\n",
    "#Feel free to convert this palette to a map\n",
    "palette = [0, 0, 0, 128, 0, 0, 0, 128, 0, 128, 128, 0, 0, 0, 128, 128, 0, 128, 0, 128, 128,\n",
    "           128, 128, 128, 64, 0, 0, 192, 0, 0, 64, 128, 0, 192, 128, 0, 64, 0, 128, 192, 0, 128,\n",
    "           64, 128, 128, 192, 128, 128, 0, 64, 0, 128, 64, 0, 0, 192, 0, 128, 192, 0, 0, 64, 128]  #3 values- R,G,B for every class. First 3 values for class 0, next 3 for\n",
    "#class 1 and so on......\n",
    "\n",
    "'''\n",
    "Depending on the mode, train or val or test, the function reads the train.txt, val.txt and test.txt files and returns a list of tuples of the form\n",
    "(image_path, mask_path) for each image in the dataset, where image_path is the path to the image and mask_path is the path to the mask for that image. \n",
    "'''\n",
    "def make_dataset(mode):\n",
    "    \n",
    "    assert mode in ['train', 'val', 'test', 'trainval']\n",
    "    \n",
    "    items = []\n",
    "    img_path = os.path.join(root, 'VOCdevkit', 'VOC2007', 'JPEGImages')\n",
    "    mask_path = os.path.join(root, 'VOCdevkit', 'VOC2007', 'SegmentationClass')\n",
    "    data_list = [l.strip('\\n') for l in open(os.path.join(\n",
    "        root, 'VOCdevkit', 'VOC2007', 'ImageSets', 'Segmentation', f'{mode}.txt')).readlines()]\n",
    "    for it in data_list:\n",
    "        item = (os.path.join(img_path, it + '.jpg'), os.path.join(mask_path, it + '.png'))\n",
    "        items.append(item)\n",
    "\n",
    "        \n",
    "    return items\n",
    "\n",
    "\n",
    "'''\n",
    "The class VOC is a subclass of the class torch.utils.data.Dataset. It overrides the __len__ and __getitem__ methods.\n",
    "The __len__ method returns the length of the dataset, i.e. the number of images in the dataset.\n",
    "The __getitem__ method returns the image and the mask for the given index.\n",
    "'''\n",
    "\n",
    "class VOC(data.Dataset):\n",
    "    def __init__(self, mode, transform=None, target_transform=None, common_transform=None):\n",
    "        self.imgs = make_dataset(mode)        \n",
    "        if len(self.imgs) == 0:\n",
    "            raise RuntimeError('Found 0 images, please check the data set')\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.common_transform = common_transform\n",
    "        self.width = 256\n",
    "        self.height = 256\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_path, mask_path = self.imgs[index]\n",
    "        img = Image.open(img_path).convert('RGB').resize((self.width, self.height))\n",
    "        mask = Image.open(mask_path).resize((self.width, self.height))\n",
    "\n",
    "        if self.common_transform is not None:\n",
    "            img, mask = self.common_transform((img,mask)) \n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            mask = self.target_transform(mask)\n",
    "\n",
    "        mask[mask==ignore_label]=0\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F9PiYKnVqZyn"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "class MaskToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.from_numpy(np.array(img, dtype=np.int32)).long()\n",
    "\n",
    "\n",
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*mean_std)\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    MaskToTensor()\n",
    "])\n",
    "\n",
    "original_train_dataset = VOC('trainval', transform=input_transform, target_transform=target_transform)\n",
    "# original_val_dataset = VOC('val', transform=input_transform, target_transform=target_transform)\n",
    "original_test_dataset = VOC('test', transform=input_transform, target_transform=target_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRm6BoBqxdzw",
    "outputId": "f68df7c5-b344-4b7e-a047-5f3cc46f4756"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "PREFETCH_FACTOR = 2 # improves data transfer speed between GPU and CPU and reduces GPU wait time\n",
    "train_loader = DataLoader(dataset=original_train_dataset, batch_size=16, shuffle=True, num_workers=NUM_WORKERS, prefetch_factor=PREFETCH_FACTOR, pin_memory=True)\n",
    "\n",
    "# val_loader = DataLoader(dataset=original_val_dataset, batch_size=16, shuffle=False, num_workers=NUM_WORKERS, prefetch_factor=PREFETCH_FACTOR, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=original_test_dataset, batch_size= 16, shuffle=False, num_workers=NUM_WORKERS, prefetch_factor=PREFETCH_FACTOR, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from torchvision.datasets import Cityscapes\n",
    "\n",
    "# data_dir = \"./data/cityscapes\"\n",
    "\n",
    "# train_dataset = Cityscapes(root=data_dir, split=\"train\", mode=\"fine\", target_type=\"semantic\", transform=input_transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCiDan5JzXVS"
   },
   "source": [
    "# utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Y4wq8Kp_UtHf"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def iou(pred, target, n_classes = 21):\n",
    "    target[target==255] = 0\n",
    "\n",
    "    ious = []\n",
    "\n",
    "    for cls in range(n_classes):\n",
    "        intersection = torch.sum((pred == cls) & (target == cls)).item()\n",
    "        union = torch.sum(pred == cls) + torch.sum(target == cls) - intersection\n",
    "        union = union.item()\n",
    "        if union!=0:\n",
    "            ious.append(intersection/union)\n",
    "\n",
    "    ious = np.array(ious)\n",
    "    return ious\n",
    "\n",
    "'''\n",
    "returns pixel accuracy for the batch\n",
    "'''\n",
    "def pixel_acc(pred, target):\n",
    "    target[target==255] = 0\n",
    "    \n",
    "    correct = torch.sum(pred==target).item()\n",
    "    total_predictions = target.shape[0]*target.shape[1]*target.shape[2]\n",
    "    return correct/total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nIMKgG9GRiel"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model=None):\n",
    "\n",
    "    model_ = model \n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    best_iou_score = 0.0\n",
    "\n",
    "    trainEpochLoss = []\n",
    "    trainEpochAccuracy = []\n",
    "    trainEpochIOU = []\n",
    "    valEpochLoss = []\n",
    "    valEpochAccuracy = []\n",
    "    valEpochIOU = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        train_iou = []\n",
    "\n",
    "        ts = time.time()\n",
    "        for itr, (inputs, labels) in enumerate(train_loader):\n",
    "            #   reset optimizer gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs =  inputs.to(device)\n",
    "            labels =   labels.to(device)\n",
    "\n",
    "            trainOutputs =  model_(inputs)\n",
    "#             trainOutputs = F.softmax(trainOutputs, dim=1)\n",
    "            loss =  criterion(trainOutputs,labels)  #  calculate loss\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # To compute accuracy and IOU\n",
    "                # outputs = F.log_softmax(model_(inputs), dim=1)\n",
    "                _, pred = torch.max(trainOutputs, dim=1)\n",
    "                \n",
    "                train_iou.append(np.mean(iou(pred, labels)))\n",
    "                train_acc.append(pixel_acc(pred, labels))\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if itr % 10 == 0:\n",
    "                print(f\"==> epoch{epoch}, iter{itr+1}, Train set=> loss: {np.mean(train_loss)}, IOU: {np.mean(train_iou)}, Acc: {np.mean(train_acc)}\")\n",
    "\n",
    "        # print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "        print(f\"Finish epoch {epoch}, time elapsed {time.time() - ts}\")\n",
    "\n",
    "        val_loss, val_iou, val_acc = test(epoch,model_)\n",
    "        model_.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UTQQ4B7hU3cd"
   },
   "outputs": [],
   "source": [
    "def test(epoch, model=None):\n",
    "    model_ = model\n",
    "    model_.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "\n",
    "    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing\n",
    "        num_iter = 0\n",
    "        for iter, (inputs, labels) in enumerate(test_loader):\n",
    "            \n",
    "            # both inputs and labels have to reside in the same device as the model's\n",
    "            inputs =  inputs.to(device)#  transfer the input to the same device as the model's\n",
    "            labels =   labels.to(device)#  transfer the labels to the same device as the model's\n",
    "\n",
    "\n",
    "            outputs = model_(inputs)\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "#             valoutputs = model_(inputs)\n",
    "            valloss = criterion(outputs, labels)\n",
    "            \n",
    "            num_iter += 1\n",
    "            _, pred = torch.max(outputs, dim=1)\n",
    "            \n",
    "            mean_iou_scores.append(np.mean(iou(pred, labels)))\n",
    "            accuracy.append(pixel_acc(pred, labels))\n",
    "            losses.append(valloss.item())\n",
    "\n",
    "    # print(mean_iou_scores, accuracy)\n",
    "    print(f\"=========> Loss at epoch {epoch} is {np.mean(losses)}\")\n",
    "    print(f\"=========> IoU at epoch {epoch} is {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"=========> Pixel acc at epoch {epoch} is {np.mean(accuracy)}\")\n",
    "\n",
    "    \n",
    "    return np.mean(losses), np.mean(mean_iou_scores), np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loHUcdGAb_Xy"
   },
   "source": [
    "# SSL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xkWyigy-PQhI"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, in_chan, out_dim):\n",
    "        super(Backbone, self).__init__()\n",
    "        \n",
    "        \n",
    "        modules = list(models.resnet18(weights=None).children())[:-1]\n",
    "        self.model = nn.Sequential(*modules)\n",
    "        self.linear = nn.Linear(512, 200)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_1Zwqss-PIJl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Segmentor(nn.Module):\n",
    "    def __init__(self, n_class=21, n_dim=512):\n",
    "        super(Segmentor, self).__init__()\n",
    "\n",
    "        # Encoder (Based on the provided SSL architecture)\n",
    "        self.encoder = Backbone(in_chan=3, out_dim=n_dim)\n",
    "        \n",
    "#         self.reducer = nn.Conv2d(256, 8, kernel_size=1)\n",
    "        \n",
    "        # do some drastic upsampling from (1,1) to (16, 16) to reduce overall parameters\n",
    "        self.drastic = nn.ConvTranspose2d(512, 256, kernel_size=(16,16), stride = 1)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder4 = self.expanding_block(256, 64)\n",
    "#         self.decoder3 = self.expanding_block(128, 64)\n",
    "        self.decoder2 = self.expanding_block(64, 32)\n",
    "#         self.decoder1 = self.expanding_block(32, 16)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "        \n",
    "    def expanding_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(out_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder (SSL model)\n",
    "        features = self.encoder(x)\n",
    "        \n",
    "#         features = self.reducer(features)\n",
    "        features = self.drastic(features)\n",
    "        \n",
    "        # Decoder\n",
    "        decode4 = self.decoder4(features)\n",
    "#         decode3 = self.decoder3(decode4)\n",
    "        decode2 = self.decoder2(decode4)\n",
    "    \n",
    "#         decode1 = self.decoder1(decode2)\n",
    "        \n",
    "        # Output\n",
    "        output = self.output(decode2)\n",
    "        output = nn.ReLU(inplace=True)(output)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZABMvHyKK0Y",
    "outputId": "0cb8e56d-9b26-45c5-dffb-4d21c4422392"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming 21 classes for segmentation\n",
    "num_classes = 21\n",
    "\n",
    "\n",
    "# Create the overall segmentor model\n",
    "model = Segmentor(n_class=num_classes, n_dim=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SSL model weights\n",
    "backbone_weights = torch.load('pet_resnet_dc_e5_c200_s8000.pth', map_location=torch.device(device))\n",
    "model.encoder.load_state_dict(backbone_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "GbCVDRxGPIRF",
    "outputId": "bcff3e81-c437-45f8-a6fa-5ca8a16ab5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> epoch0, iter1, Train set=> loss: 3.0943729877471924, IOU: 0.007042501509026087, Acc: 0.027179718017578125\n",
      "==> epoch0, iter11, Train set=> loss: 2.5892494808543813, IOU: 0.024503151442388273, Acc: 0.3325041857632724\n",
      "==> epoch0, iter21, Train set=> loss: 2.3988965352376304, IOU: 0.02929003619477605, Acc: 0.3806997480846587\n",
      "Finish epoch 0, time elapsed 4.3575849533081055\n",
      "=========> Loss at epoch 0 is 2.7919948441641673\n",
      "=========> IoU at epoch 0 is 0.03700203264091638\n",
      "=========> Pixel acc at epoch 0 is 0.4295133181980678\n",
      "==> epoch1, iter1, Train set=> loss: 1.9831830263137817, IOU: 0.03719551302506282, Acc: 0.46772003173828125\n",
      "==> epoch1, iter11, Train set=> loss: 2.0511144291270864, IOU: 0.037313662248386954, Acc: 0.4480621164495295\n",
      "==> epoch1, iter21, Train set=> loss: 1.9763928311211723, IOU: 0.03912434078903059, Acc: 0.47707044510614305\n",
      "Finish epoch 1, time elapsed 4.325148820877075\n",
      "=========> Loss at epoch 1 is 2.6823293481554304\n",
      "=========> IoU at epoch 1 is 0.051349053516317654\n",
      "=========> Pixel acc at epoch 1 is 0.6032037734985352\n",
      "==> epoch2, iter1, Train set=> loss: 1.688730239868164, IOU: 0.03843193564115774, Acc: 0.6223211288452148\n",
      "==> epoch2, iter11, Train set=> loss: 1.5164590640501543, IOU: 0.04887088178658623, Acc: 0.687730529091575\n",
      "==> epoch2, iter21, Train set=> loss: 1.3541989581925529, IOU: 0.0519193898227064, Acc: 0.7235843113490513\n",
      "Finish epoch 2, time elapsed 4.324569225311279\n",
      "=========> Loss at epoch 2 is 2.5076883009501865\n",
      "=========> IoU at epoch 2 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 2 is 0.7290957314627511\n",
      "==> epoch3, iter1, Train set=> loss: 1.2792257070541382, IOU: 0.04961382548014323, Acc: 0.7442073822021484\n",
      "==> epoch3, iter11, Train set=> loss: 1.1812003254890442, IOU: 0.05348601420174005, Acc: 0.7528579018332742\n",
      "==> epoch3, iter21, Train set=> loss: 1.2251324227878027, IOU: 0.052126743332336044, Acc: 0.7377296175275531\n",
      "Finish epoch 3, time elapsed 4.369634628295898\n",
      "=========> Loss at epoch 3 is 2.5046277216502597\n",
      "=========> IoU at epoch 3 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 3 is 0.7290957314627511\n",
      "==> epoch4, iter1, Train set=> loss: 1.3515102863311768, IOU: 0.04287594556808472, Acc: 0.6860151290893555\n",
      "==> epoch4, iter11, Train set=> loss: 1.1578588702461936, IOU: 0.05010112653420591, Acc: 0.7551098736849698\n",
      "==> epoch4, iter21, Train set=> loss: 1.2244982492356074, IOU: 0.05067447878885073, Acc: 0.7371452876499721\n",
      "Finish epoch 4, time elapsed 4.287770509719849\n",
      "=========> Loss at epoch 4 is 2.5227058274405345\n",
      "=========> IoU at epoch 4 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 4 is 0.7290957314627511\n",
      "==> epoch5, iter1, Train set=> loss: 1.246592402458191, IOU: 0.06013353665669759, Acc: 0.7216024398803711\n",
      "==> epoch5, iter11, Train set=> loss: 1.2060927802866155, IOU: 0.05398059868365312, Acc: 0.7400358373468573\n",
      "==> epoch5, iter21, Train set=> loss: 1.181409478187561, IOU: 0.05179741145886998, Acc: 0.7450619198027111\n",
      "Finish epoch 5, time elapsed 4.270085096359253\n",
      "=========> Loss at epoch 5 is 2.48210460799081\n",
      "=========> IoU at epoch 5 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 5 is 0.7290957314627511\n",
      "==> epoch6, iter1, Train set=> loss: 0.9948886632919312, IOU: 0.04832856795367073, Acc: 0.8215856552124023\n",
      "==> epoch6, iter11, Train set=> loss: 1.188785650513389, IOU: 0.04854113726329685, Acc: 0.745404676957564\n",
      "==> epoch6, iter21, Train set=> loss: 1.205850601196289, IOU: 0.04860692944132509, Acc: 0.7378823870704287\n",
      "Finish epoch 6, time elapsed 4.237550973892212\n",
      "=========> Loss at epoch 6 is 2.500977635383606\n",
      "=========> IoU at epoch 6 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 6 is 0.7290957314627511\n",
      "==> epoch7, iter1, Train set=> loss: 1.2310853004455566, IOU: 0.052522591182163784, Acc: 0.735316276550293\n",
      "==> epoch7, iter11, Train set=> loss: 1.2691470384597778, IOU: 0.04984567737162679, Acc: 0.7290858355435458\n",
      "==> epoch7, iter21, Train set=> loss: 1.18274872643607, IOU: 0.050798618222477276, Acc: 0.7456585566202799\n",
      "Finish epoch 7, time elapsed 4.2594757080078125\n",
      "=========> Loss at epoch 7 is 2.555987238883972\n",
      "=========> IoU at epoch 7 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 7 is 0.7290957314627511\n",
      "==> epoch8, iter1, Train set=> loss: 1.3358861207962036, IOU: 0.043773770332336426, Acc: 0.7003803253173828\n",
      "==> epoch8, iter11, Train set=> loss: 1.1625517986037515, IOU: 0.05314434632594451, Acc: 0.7423923665826971\n",
      "==> epoch8, iter21, Train set=> loss: 1.1871118857747032, IOU: 0.05191786949654195, Acc: 0.7395577657790411\n",
      "Finish epoch 8, time elapsed 4.322607040405273\n",
      "=========> Loss at epoch 8 is 2.565910850252424\n",
      "=========> IoU at epoch 8 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 8 is 0.7290957314627511\n",
      "==> epoch9, iter1, Train set=> loss: 1.4120017290115356, IOU: 0.04340922832489014, Acc: 0.6945476531982422\n",
      "==> epoch9, iter11, Train set=> loss: 1.1825819990851663, IOU: 0.05200464342093996, Acc: 0.7420819889415394\n",
      "==> epoch9, iter21, Train set=> loss: 1.1771002695673989, IOU: 0.052249969402911434, Acc: 0.7439615158807664\n",
      "Finish epoch 9, time elapsed 4.205012083053589\n",
      "=========> Loss at epoch 9 is 2.5374939101082936\n",
      "=========> IoU at epoch 9 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 9 is 0.7290957314627511\n",
      "==> epoch10, iter1, Train set=> loss: 1.1918610334396362, IOU: 0.047037601470947266, Acc: 0.7526016235351562\n",
      "==> epoch10, iter11, Train set=> loss: 1.0821392373605208, IOU: 0.05054321025592947, Acc: 0.7676740993152965\n",
      "==> epoch10, iter21, Train set=> loss: 1.1264092723528545, IOU: 0.050763881408432056, Acc: 0.7570744923182896\n",
      "Finish epoch 10, time elapsed 4.299672365188599\n",
      "=========> Loss at epoch 10 is 2.490992001124791\n",
      "=========> IoU at epoch 10 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 10 is 0.7290957314627511\n",
      "==> epoch11, iter1, Train set=> loss: 1.3672887086868286, IOU: 0.04825060708182199, Acc: 0.6755084991455078\n",
      "==> epoch11, iter11, Train set=> loss: 1.2402346892790361, IOU: 0.04997021076959489, Acc: 0.7185420989990234\n",
      "==> epoch11, iter21, Train set=> loss: 1.1770846815336318, IOU: 0.050997962594884004, Acc: 0.741354124886649\n",
      "Finish epoch 11, time elapsed 4.252030372619629\n",
      "=========> Loss at epoch 11 is 2.5486293690545216\n",
      "=========> IoU at epoch 11 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 11 is 0.7290957314627511\n",
      "==> epoch12, iter1, Train set=> loss: 1.5180232524871826, IOU: 0.047826326810396634, Acc: 0.6217422485351562\n",
      "==> epoch12, iter11, Train set=> loss: 1.1728187691081653, IOU: 0.049945082509859295, Acc: 0.7447832280939276\n",
      "==> epoch12, iter21, Train set=> loss: 1.1855624601954506, IOU: 0.05055205507935322, Acc: 0.7410668418520973\n",
      "Finish epoch 12, time elapsed 4.223608016967773\n",
      "=========> Loss at epoch 12 is 2.53433586869921\n",
      "=========> IoU at epoch 12 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 12 is 0.7290957314627511\n",
      "==> epoch13, iter1, Train set=> loss: 1.0902281999588013, IOU: 0.04563993215560913, Acc: 0.7302389144897461\n",
      "==> epoch13, iter11, Train set=> loss: 1.2348020618612117, IOU: 0.04952653229956982, Acc: 0.7227469357577238\n",
      "==> epoch13, iter21, Train set=> loss: 1.2024395834831965, IOU: 0.04999566802241104, Acc: 0.7298790159679595\n",
      "Finish epoch 13, time elapsed 4.266844749450684\n",
      "=========> Loss at epoch 13 is 2.559979030064174\n",
      "=========> IoU at epoch 13 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 13 is 0.7290957314627511\n",
      "==> epoch14, iter1, Train set=> loss: 1.0378010272979736, IOU: 0.059248704176682696, Acc: 0.770233154296875\n",
      "==> epoch14, iter11, Train set=> loss: 1.1581739783287048, IOU: 0.050048062817130805, Acc: 0.7409657565030184\n",
      "==> epoch14, iter21, Train set=> loss: 1.1613067445300875, IOU: 0.051511457624892974, Acc: 0.7438449859619141\n",
      "Finish epoch 14, time elapsed 4.29175066947937\n",
      "=========> Loss at epoch 14 is 2.564296007156372\n",
      "=========> IoU at epoch 14 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 14 is 0.7290957314627511\n",
      "==> epoch15, iter1, Train set=> loss: 1.095304250717163, IOU: 0.054035731724330356, Acc: 0.756500244140625\n",
      "==> epoch15, iter11, Train set=> loss: 1.2549896836280823, IOU: 0.04937790780059878, Acc: 0.7157077789306641\n",
      "==> epoch15, iter21, Train set=> loss: 1.1684809043293907, IOU: 0.051097970853385306, Acc: 0.7390218916393462\n",
      "Finish epoch 15, time elapsed 4.294902086257935\n",
      "=========> Loss at epoch 15 is 2.5152333974838257\n",
      "=========> IoU at epoch 15 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 15 is 0.7290957314627511\n",
      "==> epoch16, iter1, Train set=> loss: 0.9706761240959167, IOU: 0.043767480289234835, Acc: 0.7440471649169922\n",
      "==> epoch16, iter11, Train set=> loss: 1.1389443440870806, IOU: 0.05091761921213875, Acc: 0.7382607893510298\n",
      "==> epoch16, iter21, Train set=> loss: 1.1807860419863747, IOU: 0.050857239553765234, Acc: 0.7357567832583473\n",
      "Finish epoch 16, time elapsed 4.248939037322998\n",
      "=========> Loss at epoch 16 is 2.519656538963318\n",
      "=========> IoU at epoch 16 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 16 is 0.7290957314627511\n",
      "==> epoch17, iter1, Train set=> loss: 1.03107750415802, IOU: 0.050087153911590576, Acc: 0.8013944625854492\n",
      "==> epoch17, iter11, Train set=> loss: 1.1222324208779768, IOU: 0.050876666024178126, Acc: 0.7416702617298473\n",
      "==> epoch17, iter21, Train set=> loss: 1.1392782245363509, IOU: 0.05062634382646574, Acc: 0.7417361395699638\n",
      "Finish epoch 17, time elapsed 4.320367097854614\n",
      "=========> Loss at epoch 17 is 2.5069465977805003\n",
      "=========> IoU at epoch 17 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 17 is 0.7290957314627511\n",
      "==> epoch18, iter1, Train set=> loss: 0.9806198477745056, IOU: 0.0561060905456543, Acc: 0.7854852676391602\n",
      "==> epoch18, iter11, Train set=> loss: 1.0528859821232883, IOU: 0.05351314824539702, Acc: 0.7644684531471946\n",
      "==> epoch18, iter21, Train set=> loss: 1.0902281602223713, IOU: 0.054346439680176994, Acc: 0.7585342498052687\n",
      "Finish epoch 18, time elapsed 4.3373658657073975\n",
      "=========> Loss at epoch 18 is 2.5339534282684326\n",
      "=========> IoU at epoch 18 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 18 is 0.7290957314627511\n",
      "==> epoch19, iter1, Train set=> loss: 1.2262390851974487, IOU: 0.04956872122628348, Acc: 0.6939620971679688\n",
      "==> epoch19, iter11, Train set=> loss: 1.1363783099434592, IOU: 0.049852723701468024, Acc: 0.739712888544256\n",
      "==> epoch19, iter21, Train set=> loss: 1.1035180375689553, IOU: 0.050083594005618584, Acc: 0.7494303839547294\n",
      "Finish epoch 19, time elapsed 4.22183632850647\n",
      "=========> Loss at epoch 19 is 2.5418546880994524\n",
      "=========> IoU at epoch 19 is 0.05791702938389349\n",
      "=========> Pixel acc at epoch 19 is 0.7253223827907017\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train(model)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unfreeze the backbone\n",
    "# for param in model.encoder.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "    \n",
    "# # train further\n",
    "# epochs = 20\n",
    "\n",
    "# train(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
