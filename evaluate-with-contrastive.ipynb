{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thtfI8d0ad4q"
   },
   "source": [
    "# Download and unzip the PascalVoc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "ivkItYJooBYF",
    "outputId": "c787603f-3fcc-4c1b-ae42-c9dad86c22df"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "data_dir = './voc'\n",
    "\n",
    "train_dataset = torchvision.datasets.VOCSegmentation(root=data_dir, year='2007', download=False, image_set='train')\n",
    "val_dataset = torchvision.datasets.VOCSegmentation(root=data_dir, year='2007', download=False, image_set='val')\n",
    "test_dataset = torchvision.datasets.VOCSegmentation(root=data_dir, year='2007', download=False, image_set='test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 209\n",
      "Val set size: 213\n",
      "Test set size: 210\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Val set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKjin4TeaiYN"
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "\n",
    "run the code below to get thre dataloader objects, namely: train_loader, val_loader and test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1UV1V2XqkWf",
    "outputId": "04a90050-9610-4011-d28a-6adda25524e4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "num_classes = 21\n",
    "ignore_label = 255\n",
    "root = data_dir\n",
    "\n",
    "'''\n",
    "color map\n",
    "0=background, 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle # 6=bus, 7=car, 8=cat, 9=chair, 10=cow, 11=diningtable,\n",
    "12=dog, 13=horse, 14=motorbike, 15=person # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
    "'''\n",
    "\n",
    "\n",
    "#Feel free to convert this palette to a map\n",
    "palette = [0, 0, 0, 128, 0, 0, 0, 128, 0, 128, 128, 0, 0, 0, 128, 128, 0, 128, 0, 128, 128,\n",
    "           128, 128, 128, 64, 0, 0, 192, 0, 0, 64, 128, 0, 192, 128, 0, 64, 0, 128, 192, 0, 128,\n",
    "           64, 128, 128, 192, 128, 128, 0, 64, 0, 128, 64, 0, 0, 192, 0, 128, 192, 0, 0, 64, 128]  #3 values- R,G,B for every class. First 3 values for class 0, next 3 for\n",
    "#class 1 and so on......\n",
    "\n",
    "'''\n",
    "Depending on the mode, train or val or test, the function reads the train.txt, val.txt and test.txt files and returns a list of tuples of the form\n",
    "(image_path, mask_path) for each image in the dataset, where image_path is the path to the image and mask_path is the path to the mask for that image. \n",
    "'''\n",
    "def make_dataset(mode):\n",
    "    \n",
    "    assert mode in ['train', 'val', 'test', 'trainval']\n",
    "    \n",
    "    items = []\n",
    "    img_path = os.path.join(root, 'VOCdevkit', 'VOC2007', 'JPEGImages')\n",
    "    mask_path = os.path.join(root, 'VOCdevkit', 'VOC2007', 'SegmentationClass')\n",
    "    data_list = [l.strip('\\n') for l in open(os.path.join(\n",
    "        root, 'VOCdevkit', 'VOC2007', 'ImageSets', 'Segmentation', f'{mode}.txt')).readlines()]\n",
    "    for it in data_list:\n",
    "        item = (os.path.join(img_path, it + '.jpg'), os.path.join(mask_path, it + '.png'))\n",
    "        items.append(item)\n",
    "\n",
    "        \n",
    "    return items\n",
    "\n",
    "\n",
    "'''\n",
    "The class VOC is a subclass of the class torch.utils.data.Dataset. It overrides the __len__ and __getitem__ methods.\n",
    "The __len__ method returns the length of the dataset, i.e. the number of images in the dataset.\n",
    "The __getitem__ method returns the image and the mask for the given index.\n",
    "'''\n",
    "\n",
    "class VOC(data.Dataset):\n",
    "    def __init__(self, mode, transform=None, target_transform=None, common_transform=None):\n",
    "        self.imgs = make_dataset(mode)        \n",
    "        if len(self.imgs) == 0:\n",
    "            raise RuntimeError('Found 0 images, please check the data set')\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.common_transform = common_transform\n",
    "        self.width = 256\n",
    "        self.height = 256\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_path, mask_path = self.imgs[index]\n",
    "        img = Image.open(img_path).convert('RGB').resize((self.width, self.height))\n",
    "        mask = Image.open(mask_path).resize((self.width, self.height))\n",
    "\n",
    "        if self.common_transform is not None:\n",
    "            img, mask = self.common_transform((img,mask)) \n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            mask = self.target_transform(mask)\n",
    "\n",
    "        mask[mask==ignore_label]=0\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F9PiYKnVqZyn"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "class MaskToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.from_numpy(np.array(img, dtype=np.int32)).long()\n",
    "\n",
    "\n",
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "input_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*mean_std)\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    MaskToTensor()\n",
    "])\n",
    "\n",
    "original_train_dataset = VOC('trainval', transform=input_transform, target_transform=target_transform)\n",
    "# original_val_dataset = VOC('val', transform=input_transform, target_transform=target_transform)\n",
    "original_test_dataset = VOC('test', transform=input_transform, target_transform=target_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRm6BoBqxdzw",
    "outputId": "f68df7c5-b344-4b7e-a047-5f3cc46f4756"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "PREFETCH_FACTOR = 2 # improves data transfer speed between GPU and CPU and reduces GPU wait time\n",
    "train_loader = DataLoader(dataset=original_train_dataset, batch_size=16, shuffle=True, num_workers=NUM_WORKERS, prefetch_factor=PREFETCH_FACTOR, pin_memory=True)\n",
    "\n",
    "# val_loader = DataLoader(dataset=original_val_dataset, batch_size=16, shuffle=False, num_workers=NUM_WORKERS, prefetch_factor=PREFETCH_FACTOR, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=original_test_dataset, batch_size= 16, shuffle=False, num_workers=NUM_WORKERS, prefetch_factor=PREFETCH_FACTOR, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from torchvision.datasets import Cityscapes\n",
    "\n",
    "# data_dir = \"./data/cityscapes\"\n",
    "\n",
    "# train_dataset = Cityscapes(root=data_dir, split=\"train\", mode=\"fine\", target_type=\"semantic\", transform=input_transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCiDan5JzXVS"
   },
   "source": [
    "# utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Y4wq8Kp_UtHf"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def iou(pred, target, n_classes = 21):\n",
    "    target[target==255] = 0\n",
    "\n",
    "    ious = []\n",
    "\n",
    "    for cls in range(n_classes):\n",
    "        intersection = torch.sum((pred == cls) & (target == cls)).item()\n",
    "        union = torch.sum(pred == cls) + torch.sum(target == cls) - intersection\n",
    "        union = union.item()\n",
    "        if union!=0:\n",
    "            ious.append(intersection/union)\n",
    "\n",
    "    ious = np.array(ious)\n",
    "    return ious\n",
    "\n",
    "'''\n",
    "returns pixel accuracy for the batch\n",
    "'''\n",
    "def pixel_acc(pred, target):\n",
    "    target[target==255] = 0\n",
    "    \n",
    "    correct = torch.sum(pred==target).item()\n",
    "    total_predictions = target.shape[0]*target.shape[1]*target.shape[2]\n",
    "    return correct/total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nIMKgG9GRiel"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model=None):\n",
    "\n",
    "    model_ = model \n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    best_iou_score = 0.0\n",
    "\n",
    "    trainEpochLoss = []\n",
    "    trainEpochAccuracy = []\n",
    "    trainEpochIOU = []\n",
    "    valEpochLoss = []\n",
    "    valEpochAccuracy = []\n",
    "    valEpochIOU = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        train_iou = []\n",
    "\n",
    "        ts = time.time()\n",
    "        for itr, (inputs, labels) in enumerate(train_loader):\n",
    "            #   reset optimizer gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs =  inputs.to(device)\n",
    "            labels =   labels.to(device)\n",
    "\n",
    "            trainOutputs =  model_(inputs)\n",
    "#             trainOutputs = F.softmax(trainOutputs, dim=1)\n",
    "            loss =  criterion(trainOutputs,labels)  #  calculate loss\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # To compute accuracy and IOU\n",
    "                # outputs = F.log_softmax(model_(inputs), dim=1)\n",
    "                _, pred = torch.max(trainOutputs, dim=1)\n",
    "                \n",
    "                train_iou.append(np.mean(iou(pred, labels)))\n",
    "                train_acc.append(pixel_acc(pred, labels))\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if itr % 10 == 0:\n",
    "                print(f\"==> epoch{epoch}, iter{itr+1}, Train set=> loss: {np.mean(train_loss)}, IOU: {np.mean(train_iou)}, Acc: {np.mean(train_acc)}\")\n",
    "\n",
    "        # print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "        print(f\"Finish epoch {epoch}, time elapsed {time.time() - ts}\")\n",
    "\n",
    "        val_loss, val_iou, val_acc = test(epoch,model_)\n",
    "        model_.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UTQQ4B7hU3cd"
   },
   "outputs": [],
   "source": [
    "def test(epoch, model=None):\n",
    "    model_ = model\n",
    "    model_.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "\n",
    "    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing\n",
    "        num_iter = 0\n",
    "        for iter, (inputs, labels) in enumerate(test_loader):\n",
    "            \n",
    "            # both inputs and labels have to reside in the same device as the model's\n",
    "            inputs =  inputs.to(device)#  transfer the input to the same device as the model's\n",
    "            labels =   labels.to(device)#  transfer the labels to the same device as the model's\n",
    "\n",
    "\n",
    "            outputs = model_(inputs)\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "#             valoutputs = model_(inputs)\n",
    "            valloss = criterion(outputs, labels)\n",
    "            \n",
    "            num_iter += 1\n",
    "            _, pred = torch.max(outputs, dim=1)\n",
    "            \n",
    "            mean_iou_scores.append(np.mean(iou(pred, labels)))\n",
    "            accuracy.append(pixel_acc(pred, labels))\n",
    "            losses.append(valloss.item())\n",
    "\n",
    "    # print(mean_iou_scores, accuracy)\n",
    "    print(f\"=========> Loss at epoch {epoch} is {np.mean(losses)}\")\n",
    "    print(f\"=========> IoU at epoch {epoch} is {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"=========> Pixel acc at epoch {epoch} is {np.mean(accuracy)}\")\n",
    "\n",
    "    \n",
    "    return np.mean(losses), np.mean(mean_iou_scores), np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loHUcdGAb_Xy"
   },
   "source": [
    "# SSL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xkWyigy-PQhI"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, in_chan, out_dim):\n",
    "        super(Backbone, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_chan, out_channels=16, kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)        \n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=256, out_features=out_dim)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        \n",
    "        self.classifier = nn.Linear(out_dim, 20)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = self.relu3(self.bn3(self.conv3(x)))\n",
    "\n",
    "        x = self.relu4(self.bn4(self.conv4(x)))\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.relu5(self.bn5(self.conv5(x)))\n",
    "        x = self.maxpool5(x)\n",
    "\n",
    "        x = self.pooling(x)\n",
    "#         embed = self.fc(x.squeeze())\n",
    "        \n",
    "#         x = self.relu6(embed)\n",
    "#         x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_1Zwqss-PIJl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Segmentor(nn.Module):\n",
    "    def __init__(self, n_class=21, n_dim=512):\n",
    "        super(Segmentor, self).__init__()\n",
    "\n",
    "        # Encoder (Based on the provided SSL architecture)\n",
    "        self.encoder = Backbone(in_chan=3, out_dim=n_dim)\n",
    "        \n",
    "#         self.reducer = nn.Conv2d(256, 8, kernel_size=1)\n",
    "        \n",
    "        # do some drastic upsampling from (1,1) to (16, 16) to reduce overall parameters\n",
    "        self.drastic = nn.ConvTranspose2d(256, 256, kernel_size=(16,16), stride = 1)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder4 = self.expanding_block(256, 64)\n",
    "#         self.decoder3 = self.expanding_block(128, 64)\n",
    "        self.decoder2 = self.expanding_block(64, 32)\n",
    "#         self.decoder1 = self.expanding_block(32, 16)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "        \n",
    "    def expanding_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(out_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder (SSL model)\n",
    "        features = self.encoder(x)\n",
    "        \n",
    "#         features = self.reducer(features)\n",
    "        features = self.drastic(features)\n",
    "        \n",
    "        # Decoder\n",
    "        decode4 = self.decoder4(features)\n",
    "#         decode3 = self.decoder3(decode4)\n",
    "        decode2 = self.decoder2(decode4)\n",
    "    \n",
    "#         decode1 = self.decoder1(decode2)\n",
    "        \n",
    "        # Output\n",
    "        output = self.output(decode2)\n",
    "        output = nn.ReLU(inplace=True)(output)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZABMvHyKK0Y",
    "outputId": "0cb8e56d-9b26-45c5-dffb-4d21c4422392"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming 21 classes for segmentation\n",
    "num_classes = 21\n",
    "\n",
    "# Create the overall segmentor model\n",
    "model = Segmentor(n_class=num_classes, n_dim=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SSL model weights\n",
    "# backbone_weights = torch.load('pet_data_dc_e20.pth', map_location=torch.device(device))\n",
    "# model.encoder.load_state_dict(backbone_weights)\n",
    "\n",
    "# # freeze the backbone\n",
    "# for param in model.encoder.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0025)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "GbCVDRxGPIRF",
    "outputId": "bcff3e81-c437-45f8-a6fa-5ca8a16ab5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> epoch0, iter1, Train set=> loss: 2.9825336933135986, IOU: 0.008565173917214737, Acc: 0.055332183837890625\n",
      "==> epoch0, iter11, Train set=> loss: 2.638412670655684, IOU: 0.027129403039298505, Acc: 0.4146718111905185\n",
      "==> epoch0, iter21, Train set=> loss: 2.4523055099305653, IOU: 0.03542650354071118, Acc: 0.486954234895252\n",
      "Finish epoch 0, time elapsed 9.29441237449646\n",
      "=========> Loss at epoch 0 is 2.8679775340216502\n",
      "=========> IoU at epoch 0 is 0.04805766794990152\n",
      "=========> Pixel acc at epoch 0 is 0.550309453691755\n",
      "==> epoch1, iter1, Train set=> loss: 1.966254472732544, IOU: 0.051775299316090935, Acc: 0.5930366516113281\n",
      "==> epoch1, iter11, Train set=> loss: 1.908684578808871, IOU: 0.0432814828988641, Acc: 0.5786150152033026\n",
      "==> epoch1, iter21, Train set=> loss: 1.8871495156061082, IOU: 0.042558514593192376, Acc: 0.5656367710658482\n",
      "Finish epoch 1, time elapsed 7.2943689823150635\n",
      "=========> Loss at epoch 1 is 2.7081760338374545\n",
      "=========> IoU at epoch 1 is 0.04808073280926545\n",
      "=========> Pixel acc at epoch 1 is 0.5505890846252441\n",
      "==> epoch2, iter1, Train set=> loss: 1.7446649074554443, IOU: 0.05551849111228508, Acc: 0.5649986267089844\n",
      "==> epoch2, iter11, Train set=> loss: 1.7404911843213169, IOU: 0.04456188224732311, Acc: 0.560370618646795\n",
      "==> epoch2, iter21, Train set=> loss: 1.7091916856311618, IOU: 0.04497586096955871, Acc: 0.5666473025367373\n",
      "Finish epoch 2, time elapsed 7.255198001861572\n",
      "=========> Loss at epoch 2 is 2.6835635730198453\n",
      "=========> IoU at epoch 2 is 0.04805204093730135\n",
      "=========> Pixel acc at epoch 2 is 0.5502337728227887\n",
      "==> epoch3, iter1, Train set=> loss: 1.7680350542068481, IOU: 0.0416960979845052, Acc: 0.5529050827026367\n",
      "==> epoch3, iter11, Train set=> loss: 1.7141823985359885, IOU: 0.04274574214884175, Acc: 0.5601198023015802\n",
      "==> epoch3, iter21, Train set=> loss: 1.6964543603715443, IOU: 0.04469265714720313, Acc: 0.5649206978934151\n",
      "Finish epoch 3, time elapsed 7.2598888874053955\n",
      "=========> Loss at epoch 3 is 2.694247211728777\n",
      "=========> IoU at epoch 3 is 0.04879067979799069\n",
      "=========> Pixel acc at epoch 3 is 0.5590767179216657\n",
      "==> epoch4, iter1, Train set=> loss: 1.7644319534301758, IOU: 0.0364255456009582, Acc: 0.5458440780639648\n",
      "==> epoch4, iter11, Train set=> loss: 1.6840654719959607, IOU: 0.04622219854427206, Acc: 0.5712394714355469\n",
      "==> epoch4, iter21, Train set=> loss: 1.6947234812236966, IOU: 0.045250295544483086, Acc: 0.5749912261962891\n",
      "Finish epoch 4, time elapsed 7.266751766204834\n",
      "=========> Loss at epoch 4 is 2.667390125138419\n",
      "=========> IoU at epoch 4 is 0.05084482520815553\n",
      "=========> Pixel acc at epoch 4 is 0.6017227172851562\n",
      "==> epoch5, iter1, Train set=> loss: 1.8288335800170898, IOU: 0.046749357522124446, Acc: 0.5606517791748047\n",
      "==> epoch5, iter11, Train set=> loss: 1.6733319542624734, IOU: 0.04696148373706999, Acc: 0.6018140099265359\n",
      "==> epoch5, iter21, Train set=> loss: 1.6847391185306368, IOU: 0.04502435262694685, Acc: 0.6003289903913226\n",
      "Finish epoch 5, time elapsed 7.246058225631714\n",
      "=========> Loss at epoch 5 is 2.7021059819630215\n",
      "=========> IoU at epoch 5 is 0.04586287392592751\n",
      "=========> Pixel acc at epoch 5 is 0.5962704930986676\n",
      "==> epoch6, iter1, Train set=> loss: 2.005906820297241, IOU: 0.0438005382502715, Acc: 0.5402097702026367\n",
      "==> epoch6, iter11, Train set=> loss: 1.6555313630537554, IOU: 0.04764641401394709, Acc: 0.6283157522028143\n",
      "==> epoch6, iter21, Train set=> loss: 1.6286830731800623, IOU: 0.046339117980936796, Acc: 0.6301122392926898\n",
      "Finish epoch 6, time elapsed 7.265005826950073\n",
      "=========> Loss at epoch 6 is 2.6679061480930875\n",
      "=========> IoU at epoch 6 is 0.05207104482532941\n",
      "=========> Pixel acc at epoch 6 is 0.6582788739885602\n",
      "==> epoch7, iter1, Train set=> loss: 1.5192660093307495, IOU: 0.04995286586560313, Acc: 0.6675577163696289\n",
      "==> epoch7, iter11, Train set=> loss: 1.4746587059714578, IOU: 0.05062033300992131, Acc: 0.6710968017578125\n",
      "==> epoch7, iter21, Train set=> loss: 1.360874096552531, IOU: 0.05040774689028128, Acc: 0.7039776302519298\n",
      "Finish epoch 7, time elapsed 7.352792024612427\n",
      "=========> Loss at epoch 7 is 2.509422319275992\n",
      "=========> IoU at epoch 7 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 7 is 0.7290957314627511\n",
      "==> epoch8, iter1, Train set=> loss: 1.1350284814834595, IOU: 0.049143314361572266, Acc: 0.7862930297851562\n",
      "==> epoch8, iter11, Train set=> loss: 1.2236937338655645, IOU: 0.04661706958822074, Acc: 0.7366308732466265\n",
      "==> epoch8, iter21, Train set=> loss: 1.1868831458545865, IOU: 0.04856630866673186, Acc: 0.748812857128325\n",
      "Finish epoch 8, time elapsed 7.285470485687256\n",
      "=========> Loss at epoch 8 is 2.519367115838187\n",
      "=========> IoU at epoch 8 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 8 is 0.7290957314627511\n",
      "==> epoch9, iter1, Train set=> loss: 1.2652192115783691, IOU: 0.0506181035723005, Acc: 0.708653450012207\n",
      "==> epoch9, iter11, Train set=> loss: 1.1585445241494612, IOU: 0.0519939425157141, Acc: 0.7550222223455255\n",
      "==> epoch9, iter21, Train set=> loss: 1.1837972402572632, IOU: 0.05102582594297809, Acc: 0.7449485233851841\n",
      "Finish epoch 9, time elapsed 7.326494455337524\n",
      "=========> Loss at epoch 9 is 2.504041450364249\n",
      "=========> IoU at epoch 9 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 9 is 0.7290957314627511\n",
      "==> epoch10, iter1, Train set=> loss: 1.0798710584640503, IOU: 0.05831718444824219, Acc: 0.7581233978271484\n",
      "==> epoch10, iter11, Train set=> loss: 1.2121912891214544, IOU: 0.05097584927019715, Acc: 0.7382995432073419\n",
      "==> epoch10, iter21, Train set=> loss: 1.178667704264323, IOU: 0.05153173364632928, Acc: 0.7447486604963031\n",
      "Finish epoch 10, time elapsed 7.24372673034668\n",
      "=========> Loss at epoch 10 is 2.550686853272574\n",
      "=========> IoU at epoch 10 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 10 is 0.7290957314627511\n",
      "==> epoch11, iter1, Train set=> loss: 0.9695029258728027, IOU: 0.05508569081624349, Acc: 0.8262853622436523\n",
      "==> epoch11, iter11, Train set=> loss: 1.26252281665802, IOU: 0.048971903276724627, Acc: 0.728267409584739\n",
      "==> epoch11, iter21, Train set=> loss: 1.1915984267280215, IOU: 0.05102634482527032, Acc: 0.7443822679065523\n",
      "Finish epoch 11, time elapsed 7.252051830291748\n",
      "=========> Loss at epoch 11 is 2.5456554549080983\n",
      "=========> IoU at epoch 11 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 11 is 0.7290957314627511\n",
      "==> epoch12, iter1, Train set=> loss: 1.5892895460128784, IOU: 0.045655250549316406, Acc: 0.6848287582397461\n",
      "==> epoch12, iter11, Train set=> loss: 1.1550718166611411, IOU: 0.051982087658723364, Acc: 0.7510586651888761\n",
      "==> epoch12, iter21, Train set=> loss: 1.1957736951964242, IOU: 0.05147763827453476, Acc: 0.7433051154727027\n",
      "Finish epoch 12, time elapsed 7.286059141159058\n",
      "=========> Loss at epoch 12 is 2.524274774960109\n",
      "=========> IoU at epoch 12 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 12 is 0.7290957314627511\n",
      "==> epoch13, iter1, Train set=> loss: 0.988865852355957, IOU: 0.0531548817952474, Acc: 0.7973232269287109\n",
      "==> epoch13, iter11, Train set=> loss: 1.248117517341267, IOU: 0.04998425583711359, Acc: 0.7283939014781605\n",
      "==> epoch13, iter21, Train set=> loss: 1.1971965432167053, IOU: 0.0511125797723227, Acc: 0.7440738677978516\n",
      "Finish epoch 13, time elapsed 7.2571120262146\n",
      "=========> Loss at epoch 13 is 2.537162286894662\n",
      "=========> IoU at epoch 13 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 13 is 0.7290957314627511\n",
      "==> epoch14, iter1, Train set=> loss: 1.0352213382720947, IOU: 0.06057035006009615, Acc: 0.78741455078125\n",
      "==> epoch14, iter11, Train set=> loss: 1.1562840288335627, IOU: 0.05470111955233499, Acc: 0.7505013725974343\n",
      "==> epoch14, iter21, Train set=> loss: 1.187011684690203, IOU: 0.054043406002634506, Acc: 0.7448645546322777\n",
      "Finish epoch 14, time elapsed 7.346174716949463\n",
      "=========> Loss at epoch 14 is 2.5533439261572703\n",
      "=========> IoU at epoch 14 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 14 is 0.7290957314627511\n",
      "==> epoch15, iter1, Train set=> loss: 1.119088888168335, IOU: 0.044218599796295166, Acc: 0.7074975967407227\n",
      "==> epoch15, iter11, Train set=> loss: 1.1471810720183633, IOU: 0.050099722184746516, Acc: 0.7459735003384677\n",
      "==> epoch15, iter21, Train set=> loss: 1.182445159980229, IOU: 0.05034422037458224, Acc: 0.7409202938988095\n",
      "Finish epoch 15, time elapsed 7.250230312347412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========> Loss at epoch 15 is 2.517987404550825\n",
      "=========> IoU at epoch 15 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 15 is 0.7290957314627511\n",
      "==> epoch16, iter1, Train set=> loss: 1.3903385400772095, IOU: 0.0451473871866862, Acc: 0.677210807800293\n",
      "==> epoch16, iter11, Train set=> loss: 1.2385356426239014, IOU: 0.05039929832964485, Acc: 0.7242961363358931\n",
      "==> epoch16, iter21, Train set=> loss: 1.1717378837721688, IOU: 0.052043365292604594, Acc: 0.7432876768566313\n",
      "Finish epoch 16, time elapsed 7.358681678771973\n",
      "=========> Loss at epoch 16 is 2.5337564774921963\n",
      "=========> IoU at epoch 16 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 16 is 0.7290957314627511\n",
      "==> epoch17, iter1, Train set=> loss: 1.2266993522644043, IOU: 0.0562292979313777, Acc: 0.7309808731079102\n",
      "==> epoch17, iter11, Train set=> loss: 1.098292583769018, IOU: 0.05465734555661457, Acc: 0.7604439475319602\n",
      "==> epoch17, iter21, Train set=> loss: 1.177521146479107, IOU: 0.05242506798362262, Acc: 0.7451444353376117\n",
      "Finish epoch 17, time elapsed 7.276521682739258\n",
      "=========> Loss at epoch 17 is 2.53602773802621\n",
      "=========> IoU at epoch 17 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 17 is 0.7290957314627511\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> epoch0, iter1, Train set=> loss: 3.0092945098876953, IOU: 0.00622066843993406, Acc: 0.03785419464111328\n",
      "==> epoch0, iter11, Train set=> loss: 2.7170171304182573, IOU: 0.02717147469512641, Acc: 0.3603216518055309\n",
      "==> epoch0, iter21, Train set=> loss: 2.57073712348938, IOU: 0.03393305857502766, Acc: 0.4372586295718238\n",
      "Finish epoch 0, time elapsed 9.195792198181152\n",
      "=========> Loss at epoch 0 is 3.0226228748049055\n",
      "=========> IoU at epoch 0 is 0.04670802049448038\n",
      "=========> Pixel acc at epoch 0 is 0.6369955199105399\n",
      "==> epoch1, iter1, Train set=> loss: 1.9593805074691772, IOU: 0.03935642219430873, Acc: 0.6270961761474609\n",
      "==> epoch1, iter11, Train set=> loss: 2.000320141965693, IOU: 0.043674859470311585, Acc: 0.5713292035189542\n",
      "==> epoch1, iter21, Train set=> loss: 1.9313550563085646, IOU: 0.04415074929216892, Acc: 0.5687716801961263\n",
      "Finish epoch 1, time elapsed 7.29560661315918\n",
      "=========> Loss at epoch 1 is 2.8765545231955394\n",
      "=========> IoU at epoch 1 is 0.04590464831053393\n",
      "=========> Pixel acc at epoch 1 is 0.5500495774405343\n",
      "==> epoch2, iter1, Train set=> loss: 1.6181833744049072, IOU: 0.04385386265059891, Acc: 0.6075153350830078\n",
      "==> epoch2, iter11, Train set=> loss: 1.7126036448912187, IOU: 0.04400029006137927, Acc: 0.5733529004183683\n",
      "==> epoch2, iter21, Train set=> loss: 1.719358307974679, IOU: 0.044529615159474574, Acc: 0.5681229091825939\n",
      "Finish epoch 2, time elapsed 7.264376401901245\n",
      "=========> Loss at epoch 2 is 2.6942488636289323\n",
      "=========> IoU at epoch 2 is 0.04837922655375446\n",
      "=========> Pixel acc at epoch 2 is 0.5554448536464146\n",
      "==> epoch3, iter1, Train set=> loss: 1.8380236625671387, IOU: 0.04055304856336708, Acc: 0.538691520690918\n",
      "==> epoch3, iter11, Train set=> loss: 1.7011615363034336, IOU: 0.04074686529779018, Acc: 0.5686197280883789\n",
      "==> epoch3, iter21, Train set=> loss: 1.6986515011106218, IOU: 0.04345010242041388, Acc: 0.5695121401832217\n",
      "Finish epoch 3, time elapsed 7.276536464691162\n",
      "=========> Loss at epoch 3 is 2.652616432734898\n",
      "=========> IoU at epoch 3 is 0.04906115405094331\n",
      "=========> Pixel acc at epoch 3 is 0.5660293442862374\n",
      "==> epoch4, iter1, Train set=> loss: 1.6666555404663086, IOU: 0.0429059409172631, Acc: 0.5862283706665039\n",
      "==> epoch4, iter11, Train set=> loss: 1.6775968725031072, IOU: 0.044451739368202355, Acc: 0.5804936669089578\n",
      "==> epoch4, iter21, Train set=> loss: 1.6306164718809582, IOU: 0.046974891928790175, Acc: 0.6001527422950381\n",
      "Finish epoch 4, time elapsed 7.226336479187012\n",
      "=========> Loss at epoch 4 is 2.6083938905170987\n",
      "=========> IoU at epoch 4 is 0.05235640832283379\n",
      "=========> Pixel acc at epoch 4 is 0.6211865970066616\n",
      "==> epoch5, iter1, Train set=> loss: 1.5431784391403198, IOU: 0.04993668220535071, Acc: 0.6330490112304688\n",
      "==> epoch5, iter11, Train set=> loss: 1.5377061692151157, IOU: 0.04843840253560585, Acc: 0.6284432844682173\n",
      "==> epoch5, iter21, Train set=> loss: 1.5087019488925026, IOU: 0.048458082360996545, Acc: 0.6373616173153832\n",
      "Finish epoch 5, time elapsed 7.208146095275879\n",
      "=========> Loss at epoch 5 is 2.5901494196483066\n",
      "=========> IoU at epoch 5 is 0.05295654654265934\n",
      "=========> Pixel acc at epoch 5 is 0.6334703990391323\n",
      "==> epoch6, iter1, Train set=> loss: 1.543915867805481, IOU: 0.043559240574503263, Acc: 0.6271677017211914\n",
      "==> epoch6, iter11, Train set=> loss: 1.3695922006260266, IOU: 0.04832525308206783, Acc: 0.6880290291526101\n",
      "==> epoch6, iter21, Train set=> loss: 1.340384875025068, IOU: 0.051957236527310054, Acc: 0.7060537338256836\n",
      "Finish epoch 6, time elapsed 7.236217260360718\n",
      "=========> Loss at epoch 6 is 2.501735346657889\n",
      "=========> IoU at epoch 6 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 6 is 0.7290957314627511\n",
      "==> epoch7, iter1, Train set=> loss: 1.4104809761047363, IOU: 0.04363483190536499, Acc: 0.6981573104858398\n",
      "==> epoch7, iter11, Train set=> loss: 1.2286701527508823, IOU: 0.04888903214463798, Acc: 0.743127476085316\n",
      "==> epoch7, iter21, Train set=> loss: 1.2243444919586182, IOU: 0.050069316044432335, Acc: 0.7423675173804873\n",
      "Finish epoch 7, time elapsed 7.2514379024505615\n",
      "=========> Loss at epoch 7 is 2.509525111743382\n",
      "=========> IoU at epoch 7 is 0.05576357488509349\n",
      "=========> Pixel acc at epoch 7 is 0.7290957314627511\n",
      "==> epoch8, iter1, Train set=> loss: 1.0145106315612793, IOU: 0.047106967252843523, Acc: 0.8008184432983398\n",
      "==> epoch8, iter11, Train set=> loss: 1.2212458578023044, IOU: 0.05029237595751681, Acc: 0.7435938228260387\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10707/1035513930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_10707/3678956933.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#             trainOutputs = F.softmax(trainOutputs, dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainOutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#  calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# unfreeze the backbone\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "    \n",
    "# train further\n",
    "epochs = 20\n",
    "\n",
    "train(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
