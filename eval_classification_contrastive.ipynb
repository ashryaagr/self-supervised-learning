{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b152109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 21:22:46.611942: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-09 21:22:47.691664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fec99ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self, in_chan=3, out_dim=512):\n",
    "        super(Backbone, self).__init__()\n",
    "        \n",
    "        modules = list(models.resnet18(weights=None).children())[:-1]\n",
    "        self.model = nn.Sequential(*modules)\n",
    "        self.linear = nn.Linear(512, 200)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embed = self.model(x).squeeze()\n",
    "#         x = self.linear(embed)\n",
    "        return embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe79563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "class ClassifierNet(nn.Module):\n",
    "    def __init__(self, out_dim, num_classes):\n",
    "        super(ClassifierNet, self).__init__()\n",
    "        self.backbone = Backbone(3, out_dim)\n",
    "\n",
    "        # Add a linear layer on top\n",
    "        self.linear = nn.Linear(out_dim, num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e75d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset and dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the images to (224, 224)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # Normalize using ImageNet statistics  \n",
    "])\n",
    "\n",
    "train_dataset = datasets.Flowers102(root='./data', download=False, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = datasets.Flowers102(root='./data', download=True, transform=transform, split=\"test\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da567948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the network\n",
    "num_classes = 102\n",
    "model = ClassifierNet( out_dim=512, num_classes=num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# load in the weights\n",
    "backbone_weights = torch.load('pet_resnet_dc_e5_c200_s8000.pth', map_location=torch.device(device))\n",
    "model.backbone.load_state_dict(backbone_weights)\n",
    "\n",
    "\n",
    "# # freeze the backbone so that the gradients of the final layer don't drastically disturb it\n",
    "# for param in model.backbone.parameters():\n",
    "#     param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f0987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unfreeze the backbone\n",
    "# for param in model.backbone.parameters():\n",
    "#     param.requires_grad = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6adb32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/75], Loss: 4.6368\n",
      "Test Accuracy: 1.02%\n",
      "Epoch [2/75], Loss: 4.5625\n",
      "Test Accuracy: 2.41%\n",
      "Epoch [3/75], Loss: 4.3353\n",
      "Test Accuracy: 2.70%\n",
      "Epoch [4/75], Loss: 4.0497\n",
      "Test Accuracy: 4.85%\n",
      "Epoch [5/75], Loss: 3.8489\n",
      "Test Accuracy: 5.92%\n",
      "Epoch [6/75], Loss: 3.6864\n",
      "Test Accuracy: 7.22%\n",
      "Epoch [7/75], Loss: 3.5651\n",
      "Test Accuracy: 6.52%\n",
      "Epoch [8/75], Loss: 3.3747\n",
      "Test Accuracy: 9.45%\n",
      "Epoch [9/75], Loss: 3.1617\n",
      "Test Accuracy: 9.04%\n",
      "Epoch [10/75], Loss: 2.9048\n",
      "Test Accuracy: 10.64%\n",
      "Epoch [11/75], Loss: 2.7921\n",
      "Test Accuracy: 10.28%\n",
      "Epoch [12/75], Loss: 2.5583\n",
      "Test Accuracy: 15.35%\n",
      "Epoch [13/75], Loss: 2.2928\n",
      "Test Accuracy: 15.12%\n",
      "Epoch [14/75], Loss: 2.2320\n",
      "Test Accuracy: 14.23%\n",
      "Epoch [15/75], Loss: 1.9045\n",
      "Test Accuracy: 16.67%\n",
      "Epoch [16/75], Loss: 1.7130\n",
      "Test Accuracy: 14.26%\n",
      "Epoch [17/75], Loss: 1.4121\n",
      "Test Accuracy: 17.63%\n",
      "Epoch [18/75], Loss: 1.1051\n",
      "Test Accuracy: 17.19%\n",
      "Epoch [19/75], Loss: 0.8576\n",
      "Test Accuracy: 17.56%\n",
      "Epoch [20/75], Loss: 0.7000\n",
      "Test Accuracy: 17.81%\n",
      "Epoch [21/75], Loss: 0.5675\n",
      "Test Accuracy: 20.91%\n",
      "Epoch [22/75], Loss: 0.4259\n",
      "Test Accuracy: 19.17%\n",
      "Epoch [23/75], Loss: 0.3293\n",
      "Test Accuracy: 18.85%\n",
      "Epoch [24/75], Loss: 0.2723\n",
      "Test Accuracy: 20.25%\n",
      "Epoch [25/75], Loss: 0.2071\n",
      "Test Accuracy: 22.05%\n",
      "Epoch [26/75], Loss: 0.1707\n",
      "Test Accuracy: 22.52%\n",
      "Epoch [27/75], Loss: 0.1047\n",
      "Test Accuracy: 21.97%\n",
      "Epoch [28/75], Loss: 0.0625\n",
      "Test Accuracy: 22.72%\n",
      "Epoch [29/75], Loss: 0.0798\n",
      "Test Accuracy: 21.26%\n",
      "Epoch [30/75], Loss: 0.0827\n",
      "Test Accuracy: 20.02%\n",
      "Epoch [31/75], Loss: 0.1201\n",
      "Test Accuracy: 20.04%\n",
      "Epoch [32/75], Loss: 0.1607\n",
      "Test Accuracy: 20.70%\n",
      "Epoch [33/75], Loss: 0.1047\n",
      "Test Accuracy: 20.87%\n",
      "Epoch [34/75], Loss: 0.0663\n",
      "Test Accuracy: 20.64%\n",
      "Epoch [35/75], Loss: 0.0429\n",
      "Test Accuracy: 21.34%\n",
      "Epoch [36/75], Loss: 0.0533\n",
      "Test Accuracy: 20.10%\n",
      "Epoch [37/75], Loss: 0.0328\n",
      "Test Accuracy: 21.73%\n",
      "Epoch [38/75], Loss: 0.0252\n",
      "Test Accuracy: 22.87%\n",
      "Epoch [39/75], Loss: 0.0215\n",
      "Test Accuracy: 22.57%\n",
      "Epoch [40/75], Loss: 0.0268\n",
      "Test Accuracy: 22.17%\n",
      "Epoch [41/75], Loss: 0.0118\n",
      "Test Accuracy: 22.35%\n",
      "Epoch [42/75], Loss: 0.0182\n",
      "Test Accuracy: 22.82%\n",
      "Epoch [43/75], Loss: 0.0329\n",
      "Test Accuracy: 21.06%\n",
      "Epoch [44/75], Loss: 0.0328\n",
      "Test Accuracy: 22.20%\n",
      "Epoch [45/75], Loss: 0.0350\n",
      "Test Accuracy: 19.79%\n",
      "Epoch [46/75], Loss: 0.0476\n",
      "Test Accuracy: 20.90%\n",
      "Epoch [47/75], Loss: 0.0388\n",
      "Test Accuracy: 19.78%\n",
      "Epoch [48/75], Loss: 0.0309\n",
      "Test Accuracy: 19.27%\n",
      "Epoch [49/75], Loss: 0.0286\n",
      "Test Accuracy: 21.29%\n",
      "Epoch [50/75], Loss: 0.0247\n",
      "Test Accuracy: 21.79%\n",
      "Epoch [51/75], Loss: 0.0129\n",
      "Test Accuracy: 23.47%\n",
      "Epoch [52/75], Loss: 0.0078\n",
      "Test Accuracy: 21.84%\n",
      "Epoch [53/75], Loss: 0.0119\n",
      "Test Accuracy: 24.72%\n",
      "Epoch [54/75], Loss: 0.0094\n",
      "Test Accuracy: 21.73%\n",
      "Epoch [55/75], Loss: 0.0103\n",
      "Test Accuracy: 22.10%\n",
      "Epoch [56/75], Loss: 0.0188\n",
      "Test Accuracy: 22.67%\n",
      "Epoch [57/75], Loss: 0.0151\n",
      "Test Accuracy: 22.21%\n",
      "Epoch [58/75], Loss: 0.0154\n",
      "Test Accuracy: 22.12%\n",
      "Epoch [59/75], Loss: 0.0218\n",
      "Test Accuracy: 21.53%\n",
      "Epoch [60/75], Loss: 0.0738\n",
      "Test Accuracy: 20.12%\n",
      "Epoch [61/75], Loss: 0.0818\n",
      "Test Accuracy: 15.92%\n",
      "Epoch [62/75], Loss: 0.1124\n",
      "Test Accuracy: 17.38%\n",
      "Epoch [63/75], Loss: 0.0935\n",
      "Test Accuracy: 21.32%\n",
      "Epoch [64/75], Loss: 0.0594\n",
      "Test Accuracy: 20.57%\n",
      "Epoch [65/75], Loss: 0.0647\n",
      "Test Accuracy: 18.96%\n",
      "Epoch [66/75], Loss: 0.0906\n",
      "Test Accuracy: 19.32%\n",
      "Epoch [67/75], Loss: 0.0392\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33191/2252016071.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(\"./logs/c_dc_resnet_e5_c200_s8000\")\n",
    "\n",
    "num_epochs = 75\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Log the loss\n",
    "    writer.add_scalar('Loss/train', running_loss / len(train_dataloader), epoch)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_dataloader):.4f}')\n",
    "    \n",
    "    # Evaluation loop\n",
    "    model.eval()  # Set the network to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    if epoch==10:\n",
    "        for name, param in model.backbone.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                print(name, param.data[0])\n",
    "            break\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Get the predicted class labels\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    # Log test accuracy to TensorBoard\n",
    "    writer.add_scalar('Accuracy/Test', accuracy, epoch)\n",
    "    \n",
    "    writer.flush()\n",
    "\n",
    "# Close TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b9ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
